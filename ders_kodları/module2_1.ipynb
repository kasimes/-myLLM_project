{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d94f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kasim\\AppData\\Local\\Temp\\ipykernel_7700\\1443349770.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokens = torch.tensor(tokens).unsqueeze(0)  # Add batch dimension\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Kasim_Model.__init__() missing 2 required positional arguments: 'num_heads' and 'num_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m tokens \u001b[38;5;241m=\u001b[39m k_tokenizer\u001b[38;5;241m.\u001b[39mencode(sentence)\n\u001b[0;32m      9\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(tokens)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m k_model \u001b[38;5;241m=\u001b[39m Kasim_Model(vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(k_tokenizer\u001b[38;5;241m.\u001b[39mvocab), embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, context_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     13\u001b[0m k_model\n",
      "\u001b[1;31mTypeError\u001b[0m: Kasim_Model.__init__() missing 2 required positional arguments: 'num_heads' and 'num_layers'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from kasim_model import Kasim_Model\n",
    "from kasim_tokenizer import Tokenizer   \n",
    "\n",
    "k_tokenizer=Tokenizer(\"tokenizer.json\")\n",
    "sentence = \"the capital of united states and the capital of france\"\n",
    "tokens = k_tokenizer.encode(sentence)\n",
    "tokens = torch.tensor(tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "k_model = Kasim_Model(vocab_size=len(k_tokenizer.vocab), embed_dim=4, context_length=32)\n",
    "k_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfc1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc39b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_meanings_whith_attention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentence_meanings_whith_attention\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentence_meanings_whith_attention' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84bd9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from kasim_causal_attention import KasimCausalAttention\n",
    "\n",
    "class Kasim_Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads,output_dim,context_length,dropout_rate=0):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([KasimCausalAttention(embed_dim,output_dim,context_length,dropout_rate) for _ in range(num_heads)])\n",
    "            \n",
    "    def forward(self, x):\n",
    "        attention_outs=[]\n",
    "        for head in self.heads:\n",
    "            attention_outs.append(head(x))\n",
    "\n",
    "        return torch.cat(attention_outs, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd547db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.0153e-01,  8.0140e-01,  6.3743e-01, -1.2156e-01],\n",
       "         [ 5.9359e-01,  2.6023e-01,  7.0990e-01, -2.7597e-01],\n",
       "         [ 5.9121e-01,  1.5560e-01,  8.0502e-01, -3.3606e-01],\n",
       "         [ 4.7235e-01,  1.6914e-01,  7.4850e-01, -3.8456e-01],\n",
       "         [ 4.3381e-01,  2.0413e-01,  7.0407e-01, -3.8365e-01],\n",
       "         [ 4.2942e-01,  3.1018e-01,  6.2924e-01, -3.5284e-01],\n",
       "         [ 3.4665e-01,  3.0350e-01,  5.5264e-01, -3.4712e-01],\n",
       "         [ 2.4053e-01,  3.1924e-01,  4.1587e-01, -3.0777e-01],\n",
       "         [ 2.3679e-01,  3.0131e-01,  4.2760e-01, -3.1444e-01],\n",
       "         [ 6.6421e-02,  2.1244e-01,  2.8712e-01, -2.9416e-01],\n",
       "         [ 5.5092e-01,  7.0129e-02, -1.2498e+00,  2.5312e-01],\n",
       "         [ 4.4734e-01,  1.9993e-02, -6.2562e-01, -8.6194e-02],\n",
       "         [ 4.7610e-01,  3.2873e-03, -5.5423e-01, -1.6547e-01],\n",
       "         [ 4.7739e-01, -4.3303e-02, -5.7879e-01, -1.6255e-01],\n",
       "         [ 4.7424e-01, -6.2760e-02, -6.0745e-01, -1.2920e-01],\n",
       "         [ 4.7504e-01,  3.4339e-03, -7.9748e-01, -5.2287e-02],\n",
       "         [ 4.1153e-01,  4.0804e-02, -8.1248e-01, -1.8526e-02],\n",
       "         [ 3.9541e-01,  2.5096e-03, -7.3618e-01, -1.3346e-02],\n",
       "         [ 3.5285e-01, -4.0247e-02, -6.4435e-01, -2.2212e-02],\n",
       "         [ 2.8130e-01, -5.4114e-04, -6.0221e-01,  3.9612e-02]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mullti_head_attention = Kasim_Multi_Head_Attention(embed_dim=4, num_heads=2,output_dim=4,context_length=32)\n",
    "out=mullti_head_attention(torch.randn(1,10,4))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ee2b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8635,  0.6142,  0.2060, -1.6837],\n",
       "         [ 0.7100, -0.1613,  1.0139, -1.5626],\n",
       "         [ 0.6568, -0.3392,  1.1456, -1.4633],\n",
       "         [ 0.5256, -0.1955,  1.1824, -1.5124],\n",
       "         [ 0.4844, -0.0884,  1.1584, -1.5543],\n",
       "         [ 0.4761,  0.1525,  1.0185, -1.6471],\n",
       "         [ 0.3935,  0.2656,  1.0042, -1.6632],\n",
       "         [ 0.2618,  0.5418,  0.8856, -1.6892],\n",
       "         [ 0.2605,  0.4877,  0.9325, -1.6807],\n",
       "         [-0.0069,  0.6461,  0.9800, -1.6193],\n",
       "         [ 0.9358,  0.2381, -1.6775,  0.5036],\n",
       "         [ 1.3302,  0.2122, -1.4769, -0.0656],\n",
       "         [ 1.4502,  0.1714, -1.3365, -0.2850],\n",
       "         [ 1.4712,  0.0890, -1.3326, -0.2276],\n",
       "         [ 1.4488,  0.0483, -1.3722, -0.1249],\n",
       "         [ 1.2467,  0.2113, -1.5470,  0.0890],\n",
       "         [ 1.1350,  0.3038, -1.6095,  0.1707],\n",
       "         [ 1.1830,  0.2213, -1.5869,  0.1825],\n",
       "         [ 1.2354,  0.1350, -1.5560,  0.1855],\n",
       "         [ 1.0811,  0.2149, -1.6342,  0.3383]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kasim_layer_norm import KasimLayerNorm\n",
    "norm_layer = KasimLayerNorm(4)\n",
    "norm_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28745c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal tensor:\n",
      " tensor([[[-0.0083,  1.3480, -0.1198],\n",
      "         [ 0.7742,  0.0856,  0.8841],\n",
      "         [-2.6429, -0.1946, -0.5494],\n",
      "         [-0.4276, -1.1299,  0.8204]],\n",
      "\n",
      "        [[ 0.4477,  2.0333, -0.6188],\n",
      "         [-0.1941,  0.8728,  0.4899],\n",
      "         [ 0.0187,  0.3004, -0.1455],\n",
      "         [-0.3519,  0.7901, -0.5118]]])\n",
      "\n",
      "LayerNorm sonrası tensor:\n",
      " tensor([[[-0.6219,  1.4109, -0.7890],\n",
      "         [ 0.5458, -1.4027,  0.8569],\n",
      "         [-1.4014,  0.8649,  0.5365],\n",
      "         [-0.2255, -1.0963,  1.3218]],\n",
      "\n",
      "        [[-0.1588,  1.2964, -1.1376],\n",
      "         [-1.3225,  1.0951,  0.2274],\n",
      "         [-0.2126,  1.3169, -1.1043],\n",
      "         [-0.5647,  1.4052, -0.8405]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "Ortalama: tensor([[-3.9736e-08,  9.9341e-08,  1.9868e-08,  0.0000e+00],\n",
      "        [-7.9473e-08, -1.4901e-08,  3.9736e-08,  3.9736e-08]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "Varyans: tensor([[1.5000, 1.4999, 1.5000, 1.5000],\n",
      "        [1.5000, 1.4999, 1.4996, 1.5000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Diyelim ki elimizde 2 cümle (batch=2), her cümlede 4 token var (seq_len=4), embedding boyutu 3\n",
    "x = torch.randn(2, 4, 3)  \n",
    "print(\"Orijinal tensor:\\n\", x)\n",
    "\n",
    "# LayerNorm tanımla (embedding boyutuna göre)\n",
    "layer_norm = nn.LayerNorm(3)\n",
    "\n",
    "# LayerNorm uygula\n",
    "out = layer_norm(x)\n",
    "\n",
    "print(\"\\nLayerNorm sonrası tensor:\\n\", out)\n",
    "\n",
    "# Ortalama ve varyans kontrolü\n",
    "print(\"\\nOrtalama:\", out.mean(-1))   # Her token embeddinginin ortalaması ~0\n",
    "print(\"Varyans:\", out.var(-1))       # Her token embeddinginin varyansı ~1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99944e99",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kasim\\anaconda3\\Lib\\site-packages\\google\\protobuf\\descriptor_pool.py:1270\u001b[0m, in \u001b[0;36mDefault\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1267\u001b[0m   _DEFAULT \u001b[38;5;241m=\u001b[39m DescriptorPool()\n\u001b[1;32m-> 1270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDefault\u001b[39m():\n\u001b[0;32m   1271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _DEFAULT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "q_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "q_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4464fdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d9bd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kasim_Model(\n",
       "  (embedding): Embedding(64, 4)\n",
       "  (pos_embed): Embedding(32, 4)\n",
       "  (self_attention): Kasim_Multi_Head_Attention(\n",
       "    (multi_head_attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (projection): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (layer_norm): KasimRMSNorm()\n",
       "  (mlp): KasimMLP(\n",
       "    (gate_proj): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (up_proj): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (down_proj): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (gelu): KasimGelu()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0ad8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0454, -0.1588,  0.0000,  0.8412,  1.9546])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class KasimGelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x *(1 + torch.tanh(torch.sqrt(torch.tensor(2/ torch.pi)) * \n",
    "                                 (x + 0.044715 * torch.pow(x, 3))))\n",
    "        \n",
    "\n",
    "gelu = KasimGelu()\n",
    "gelu(torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdea1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class KasimMLP(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.gate_proj = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.up_proj = nn.Linear(embed_dim,hidden_dim)\n",
    "        self.down_proj = nn.Linear(hidden_dim, embed_dim)\n",
    "        self.gelu = KasimGelu()\n",
    "    def forward(self, x):\n",
    "        gate=self.gate_proj(x)\n",
    "        gate=self.gelu(gate)\n",
    "        up=self.up_proj(x)\n",
    "        fuse=gate*up\n",
    "        outputs=self.down_proj(fuse)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38ee1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 4])\n",
      "Output shape: torch.Size([2, 4, 4])\n",
      "Output mean: 0.3486\n",
      "Output std: 1.0652\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from kasim_multi_head_attention import Kasim_Multi_Head_Attention\n",
    "from kasim_RMSnorm import KasimRMSNorm\n",
    "from kasim_MLP import KasimMLP\n",
    "\n",
    "class KasimDecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, context_length):\n",
    "        super().__init__()\n",
    "        self.self_attention = Kasim_Multi_Head_Attention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            output_dim=embed_dim,  # Çıktı boyutu embed_dim olmalı\n",
    "            context_length=context_length,\n",
    "            dropout_rate=0.5\n",
    "        )\n",
    "        self.norm1 = KasimRMSNorm(embed_dim)\n",
    "        self.mlp = KasimMLP(embed_dim, hidden_dim=4*embed_dim)  # hidden_dim genelde 4x\n",
    "        self.norm2 = KasimRMSNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Self-attention bloğu\n",
    "        residual = x\n",
    "        x = self.norm1(x)  # Pre-normalization\n",
    "        x = self.self_attention(x)\n",
    "        x = residual + x   # Residual connection\n",
    "\n",
    "        # MLP bloğu\n",
    "        residual = x\n",
    "        x = self.norm2(x)  # Pre-normalization\n",
    "        x = self.mlp(x)\n",
    "        x = residual + x   # Residual connection\n",
    "\n",
    "        return x\n",
    "\n",
    "# Doğru boyutlarda test tensörü oluştur\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "embed_dim = 4\n",
    "\n",
    "# (batch_size, seq_len, embed_dim) boyutunda tensor\n",
    "example_tensor = torch.randn(batch_size, seq_len, embed_dim)\n",
    "\n",
    "# Model parametrelerini düzelt\n",
    "decoder_block = KasimDecoderBlock(\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=2,\n",
    "    context_length=seq_len  # seq_len ile uyumlu\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "output = decoder_block(example_tensor)\n",
    "\n",
    "# Çıktı kontrolü\n",
    "print(f\"Input shape: {example_tensor.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output mean: {output.mean().item():.4f}\")\n",
    "print(f\"Output std: {output.std().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4f933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd3e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
